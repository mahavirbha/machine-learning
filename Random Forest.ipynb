{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Random Forest.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"1TIN_AHE64bkG-Yn9U9icvNJwdVlil7N1","authorship_tag":"ABX9TyNFnTgKFaEwhwGfNnUCEAa3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"h9u-PtTekfFg","colab_type":"text"},"source":["# **Random Forest Algorithm with Python and Scikit-Learn**\n","\n","# Both Regression & Classification "]},{"cell_type":"markdown","metadata":{"id":"GIEBLMHFki02","colab_type":"text"},"source":["Random forest is a type of supervised machine learning algorithm based on ensemble learning.\n","\n","The random forest algorithm combines multiple algorithm of the same type i.e. multiple decision trees, resulting in a forest of trees.\n"," \n","  The random forest algorithm can be used for both regression and classification tasks."]},{"cell_type":"markdown","metadata":{"id":"f0ikpcm-lFJv","colab_type":"text"},"source":["## **How the Random Forest Algorithm Works**"]},{"cell_type":"markdown","metadata":{"id":"dY5LAWM5lGkF","colab_type":"text"},"source":["1.  Pick N random records from the dataset.\n","\n","2.  Build a decision tree based on these N records.\n","\n","3.  Choose the number of trees you want in your algorithm and repeat steps 1 and 2.\n","\n","4.  In case of a ***regression problem***, for a new record, each tree in the forest predicts a value for Y (output). The final value can be calculated by taking the average of all the values predicted by all the trees in forest.\n","  \n","  Or, in case of a ***classification problem***, each tree in the forest predicts the category to which the new record belongs. Finally, the new record is assigned to the category that wins the majority vote."]},{"cell_type":"markdown","metadata":{"id":"frX0FCA8mNXo","colab_type":"text"},"source":["## **Part 1: Using Random Forest for Regression**"]},{"cell_type":"markdown","metadata":{"id":"S4E95Q81mY0c","colab_type":"text"},"source":["### Problem Definition\n","The problem here is to predict the gas consumption (in millions of gallons) in 48 of the US states based on petrol tax (in cents), per capita income (dollars), paved highways (in miles) and the proportion of population with the driving license.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pfHoJOTzmmAk","colab_type":"text"},"source":["### 1. Import Libraries\n","Execute the following code to import the necessary libraries:"]},{"cell_type":"code","metadata":{"id":"MSmrTCEhk39T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599114063004,"user_tz":-330,"elapsed":1250,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gd5UqIppmzft","colab_type":"text"},"source":["### 2. Importing Dataset\n","The dataset for this problem is available at\n","[here](https://drive.google.com/file/d/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_/view)"]},{"cell_type":"code","metadata":{"id":"vvqflcwcmxeF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599114069337,"user_tz":-330,"elapsed":2076,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["dataset = pd.read_csv('/content/drive/My Drive/petrol_consumption.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"67CPz46onqlh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1599114082114,"user_tz":-330,"elapsed":1337,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}},"outputId":"80554628-2cb8-4f60-d38e-d023e6ce1ed2"},"source":["dataset.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Petrol_tax</th>\n","      <th>Average_income</th>\n","      <th>Paved_Highways</th>\n","      <th>Population_Driver_licence(%)</th>\n","      <th>Petrol_Consumption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9.0</td>\n","      <td>3571</td>\n","      <td>1976</td>\n","      <td>0.525</td>\n","      <td>541</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9.0</td>\n","      <td>4092</td>\n","      <td>1250</td>\n","      <td>0.572</td>\n","      <td>524</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9.0</td>\n","      <td>3865</td>\n","      <td>1586</td>\n","      <td>0.580</td>\n","      <td>561</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7.5</td>\n","      <td>4870</td>\n","      <td>2351</td>\n","      <td>0.529</td>\n","      <td>414</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8.0</td>\n","      <td>4399</td>\n","      <td>431</td>\n","      <td>0.544</td>\n","      <td>410</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Petrol_tax  Average_income  ...  Population_Driver_licence(%)  Petrol_Consumption\n","0         9.0            3571  ...                         0.525                 541\n","1         9.0            4092  ...                         0.572                 524\n","2         9.0            3865  ...                         0.580                 561\n","3         7.5            4870  ...                         0.529                 414\n","4         8.0            4399  ...                         0.544                 410\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"xME_xE8lpdMB","colab_type":"text"},"source":["### 3. Preparing Data For Training\n","Two tasks will be performed in this section. The first task is to divide data into 'attributes' and 'label' sets. \n","\n","The resultant data is then divided into training and test sets."]},{"cell_type":"markdown","metadata":{"id":"KtZQal48pjkw","colab_type":"text"},"source":["The following script divides data into attributes and labels:"]},{"cell_type":"code","metadata":{"id":"cIHHPuYmoHG7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599114518220,"user_tz":-330,"elapsed":1155,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["X = dataset.iloc[:, 0:4].values\n","y = dataset.iloc[:, 4].values"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNUMrZVhp06H","colab_type":"text"},"source":["Finally, let's divide the data into training and testing sets:"]},{"cell_type":"code","metadata":{"id":"VnrMeUYFpxnu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599114581337,"user_tz":-330,"elapsed":1195,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZdClUlQqY3u","colab_type":"text"},"source":["### 4. Feature Scaling\n","We know our dataset is not yet a scaled value, for instance the Average_Income field has values in the range of thousands while Petrol_tax has values in range of tens. \n","\n","Therefore, it would be beneficial to scale our data (although, as mentioned earlier, this step isn't as important for the random forests algorithm). \n","\n","To do so, we will use Scikit-Learn's StandardScaler class. Execute the following code to do so:"]},{"cell_type":"code","metadata":{"id":"SpR4-bcFqBBl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599114714162,"user_tz":-330,"elapsed":1646,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l_tNTBptq2_N","colab_type":"text"},"source":["## 5. Training the Algorithm\n","Now that we have scaled our dataset, it is time to train our random forest algorithm to solve this regression problem."]},{"cell_type":"code","metadata":{"id":"VL7rR9NRqhV1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599114829116,"user_tz":-330,"elapsed":1700,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n","regressor.fit(X_train, y_train)\n","y_pred = regressor.predict(X_test)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FhgK84EHrA_F","colab_type":"text"},"source":["The **RandomForestRegressor** class of the **sklearn.ensemble** library is used to solve regression problems via random forest.\n","\n","The most important parameter of the RandomForestRegressor class is the **n_estimators** parameter.\n","\n","This parameter defines the number of trees in the random forest. We will start with n_estimator=20 to see how our algorithm performs. "]},{"cell_type":"markdown","metadata":{"id":"eWlDlkiZrkV0","colab_type":"text"},"source":["## 6. Evaluating the Algorithm\n","The last and final step of solving a machine learning problem is to evaluate the performance of the algorithm.\n","\n","For regression problems the metrics used to evaluate an algorithm are mean absolute error, mean squared error, and root mean squared error. "]},{"cell_type":"code","metadata":{"id":"EtFBCEW4q9Yv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1599115030648,"user_tz":-330,"elapsed":1316,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}},"outputId":"e1b48baa-4a2a-4104-ff81-346b202caf03"},"source":["from sklearn import metrics\n","\n","print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n","print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Mean Absolute Error: 51.76500000000001\n","Mean Squared Error: 4216.166749999999\n","Root Mean Squared Error: 64.93201637097064\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vYqcZY2OsYvz","colab_type":"text"},"source":["# **Part 2: Using Random Forest for Classification**"]},{"cell_type":"markdown","metadata":{"id":"78HzSEJCsqQw","colab_type":"text"},"source":["### Problem Definition\n","The task here is to predict whether a bank currency note is authentic or not based on four attributes i.e. variance of the image wavelet transformed image, skewness, entropy, and curtosis of the image."]},{"cell_type":"markdown","metadata":{"id":"BAcfqn5Ms3jN","colab_type":"text"},"source":["1. Import Libraries"]},{"cell_type":"code","metadata":{"id":"Mkeu3x21rusI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599115375116,"user_tz":-330,"elapsed":1267,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b_BiuWjgtDeW","colab_type":"text"},"source":["### 2. Importing Dataset\n","The dataset can be downloaded from the following link:\n","\n","[click here](https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view)"]},{"cell_type":"code","metadata":{"id":"89-oJd-DtCvs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599115962184,"user_tz":-330,"elapsed":1457,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["dataset = pd.read_csv(\"/content/drive/My Drive/bill_authentication.csv\")"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"qYg8EwKXtqQi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1599115962862,"user_tz":-330,"elapsed":1452,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}},"outputId":"e2b9f5b6-cc1e-4150-e147-c949bbb55662"},"source":["dataset.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Variance</th>\n","      <th>Skewness</th>\n","      <th>Curtosis</th>\n","      <th>Entropy</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.62160</td>\n","      <td>8.6661</td>\n","      <td>-2.8073</td>\n","      <td>-0.44699</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.54590</td>\n","      <td>8.1674</td>\n","      <td>-2.4586</td>\n","      <td>-1.46210</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.86600</td>\n","      <td>-2.6383</td>\n","      <td>1.9242</td>\n","      <td>0.10645</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.45660</td>\n","      <td>9.5228</td>\n","      <td>-4.0112</td>\n","      <td>-3.59440</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.32924</td>\n","      <td>-4.4552</td>\n","      <td>4.5718</td>\n","      <td>-0.98880</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Variance  Skewness  Curtosis  Entropy  Class\n","0   3.62160    8.6661   -2.8073 -0.44699      0\n","1   4.54590    8.1674   -2.4586 -1.46210      0\n","2   3.86600   -2.6383    1.9242  0.10645      0\n","3   3.45660    9.5228   -4.0112 -3.59440      0\n","4   0.32924   -4.4552    4.5718 -0.98880      0"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"v5xNDUf6uHk3","colab_type":"text"},"source":["3. Preparing Data For Training"]},{"cell_type":"code","metadata":{"id":"BGbRqw_VttcJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599115963465,"user_tz":-330,"elapsed":707,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["X = dataset.iloc[:, 0:4].values\n","y = dataset.iloc[:, 4].values"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"4clDyCZtuRdZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599115964146,"user_tz":-330,"elapsed":720,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lxKlbbSkueAl","colab_type":"text"},"source":["4. Feature Scaling"]},{"cell_type":"code","metadata":{"id":"sWomKxFeuZfj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599115965330,"user_tz":-330,"elapsed":726,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VyKGtZ9nurjW","colab_type":"text"},"source":["5. Training the Algorithm"]},{"cell_type":"code","metadata":{"id":"GqfpNWZmulq5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599115968832,"user_tz":-330,"elapsed":1465,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}}},"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n","regressor.fit(X_train, y_train)\n","y_pred = regressor.predict(X_test)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DkyRzquSuzHI","colab_type":"text"},"source":["6. Evaluating the Algorithm\n","\n","For classification problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision recall, and F1 values."]},{"cell_type":"code","metadata":{"id":"1xTO7tUnuvsY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"status":"ok","timestamp":1599116415606,"user_tz":-330,"elapsed":1516,"user":{"displayName":"RoboWithSomeAI X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP1YU0MRcaj9k4-VtPDlid2eD7RVx_RBO-c1hY=s64","userId":"05733345054835048797"}},"outputId":"6741b05a-f25f-405b-b0b7-172a9736e71b"},"source":["from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","print(confusion_matrix(y_test,y_pred.round()))\n","print(classification_report(y_test,y_pred.round()))\n","print(accuracy_score(y_test, y_pred.round()))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["[[155   2]\n"," [  0 118]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       157\n","           1       0.98      1.00      0.99       118\n","\n","    accuracy                           0.99       275\n","   macro avg       0.99      0.99      0.99       275\n","weighted avg       0.99      0.99      0.99       275\n","\n","0.9927272727272727\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9YrDytf-xSHq","colab_type":"text"},"source":["The accuracy achieved for by our random forest classifier with **20 trees** is **99.27%.**\n","\n","Unlike before, changing the number of estimators for this problem didn't significantly improve the results"]},{"cell_type":"code","metadata":{"id":"xdCCwCMxvBj3","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}